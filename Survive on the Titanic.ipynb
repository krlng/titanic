{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "# Technisches und Vorwissen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Libaries and imports\n",
    "\n",
    "Zur Analyse benutzen wir die Programmiersprache Python sowie diverse weitere Bibliotheken zur Datenanalyse die als \"PyData\"-Stack zusammengefasst werden. [PyData](https://pydata.org/) ist darüber hinaus auch eine Community welche Veranstalltungen wie Vorträge, Meetups und Konferenzen organisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cfdaacbc-23a3-423d-8d4d-120939ac7383",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Data Structures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "# Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter Notebook Magic\n",
    "#sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "![Libraries](static/libs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Grundlage Python + Jupyter\n",
    "\n",
    "* Mehr Beispiele und Erklärungen zu Python: https://learnxinyminutes.com/docs/python/\n",
    "* Eine Einführung zu JupyterLab von mir: https://www.youtube.com/watch?v=aSChciAOvcE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "talk_title = \"Einführung in datengetriebene Projekte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(talk_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "my_list = [1, 2, 3, talk_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "my_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "my_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "my_talk = {\"author\": \"Nico Kreiling\", \"title\": talk_title, \"date\": \"17.2.2020\"}   \n",
    "marcels_talk = {\"author\": \"Marcel Kurovski\", \"title\": \"Recommender Systems\", \"date\": \"19.2.2020\"}   \n",
    "inovex_talks = [my_talk, marcels_talk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for talk in inovex_talks:\n",
    "    print(f'{talk[\"author\"]} hält am {talk[\"date\"]} einen Vortrag zu \"{talk[\"title\"]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tage_mit_inovex_vortrag = [talk[\"date\"] for talk in inovex_talks]\n",
    "print(set(tage_mit_inovex_vortrag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(inovex_talks)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(type(df))\n",
    "print(type(df.author))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "# Survive on the Titanic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Vorgehensweise**\n",
    "\n",
    "Unser Vorgehen innerhalb dieses Workshops orientiert sich am [CRISP-DM](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining), einem industrie unabhängigen Standarad zum Vorgehen in Data Science (ursprünglich Data Mining) Projekten.\n",
    "\n",
    "Dieser beschreibt ein iteratives Vorgehen, bei dem nach einem inhaltlichen Verständnis der Aufgabe die Daten mit einer explorativen Analyse untersucht werden. Sind die Daten und das Anforderung in einklang startet eine Modell-Entwicklungsphase, bei dem die Daten so aufbereitet werden, dass darauf basierend ein oder mehrere maschinelle Lernverfahren angewandt werden können. Entspricht dieses Modell einer ausreichenden offline güte wird es in einem entsprechendem A/B Test evaluiert und anschließend produktiviert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Crisp DM](static/crisp_dm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In dieser Phase geht es darum, die eigentliche Aufgabe zu verstehen, um ein angemessenes Vorgehen zu bestimmen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Titanic\n",
    "\n",
    "On April 15, 1912, the largest passenger liner ever made collided with an iceberg during her maiden voyage. When the Titanic sank it killed 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck resulted in such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others.\n",
    "\n",
    "The titanic.csv file contains data for 887 of the real Titanic passengers. Each row represents one person. The columns describe different attributes about the person including whether they survived (S), their age (A), their passenger-class (C), their sex (G) and the fare they paid (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "# Youtube\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ItjXTieWKyI\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Aufgabe:** Vorhersage, ob ein Passagier den Untergang der Titanic übrerlebt.\n",
    "    \n",
    "**Machine Learning Klassifikation**\n",
    "* Supervised Machine Learning\n",
    "* Klassifikation\n",
    "* Binäre Klassifikation\n",
    "\n",
    "**Keine Weiteren Einschränkungen:**\n",
    "\n",
    "* Wir müssen nicht erklären, warum wir denken, dass ein Passagier stirbt oder überlebt (Explainability)\n",
    "* Uns stehen theoretisch beliebige Rechenresourcen zur Verfügung\n",
    "* Wir sind frei in der Technologiewahl\n",
    "* Es gibt keine Gewichtung der Klassen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Mit diesem Vorwissen werden wir die gegebenen Daten analysen, um eine Aussage über die Machbarkeit der Aufgabe zu erlangen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/titanic/train.csv\")\n",
    "test  = pd.read_csv(\"./data/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3ab4c525-a5cb-4183-9468-c1dd005c4c78",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_raw = train.copy()\n",
    "test_raw  = test.copy()\n",
    "\n",
    "print(\"Train Dimensions:\", train.shape)\n",
    "print(\"Test Dimensions:\", test.shape)\n",
    "\n",
    "# preview the data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import qgrid\n",
    "col_options = {\n",
    "    'width': 70,\n",
    "}\n",
    "\n",
    "def qshow(df, ops=None):\n",
    "    if ops is None:\n",
    "        ops = dict(\n",
    "            column_options=col_options,grid_options={'forceFitColumns': True}\n",
    "        )\n",
    "    return qgrid.show_grid(df, **ops)\n",
    "\n",
    "#qshow(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Columns that only exist in Trainingsset\n",
    "set(train.columns)-set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get Datatypes\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "columns2drop = [\"PassengerId\"]\n",
    "train[columns2drop].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df.drop(columns2drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "## Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "figsize(15,5)\n",
    "sns.heatmap(train.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"training:\",train.isnull().sum())\n",
    "print(\"test:\",test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Zielvariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "figsize(15,5)\n",
    "train.Survived.value_counts().sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "## Abhängige Variablen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Passanger Class (Pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "figsize(15,5)\n",
    "train.Pclass.value_counts().sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train.groupby([\"Pclass\",\"Survived\"]).size().unstack(\"Survived\").plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ticketpreis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# peaks for survived/not survived passengers by their age\n",
    "facet = sns.FacetGrid(train, hue=\"Pclass\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train.Sex.value_counts().sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train.groupby([\"Sex\",\"Survived\"]).size().unstack(\"Survived\").plot(kind=\"pie\", subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train.Age.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train.Age.to_frame().plot(kind=\"kde\", bw_method=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# peaks for survived/not survived passengers by their age\n",
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Familienbeziehug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train.SibSp.value_counts().sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train.groupby([\"SibSp\",\"Survived\"]).size().unstack(\"Survived\").plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train.Parch.value_counts().sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train.groupby([\"Parch\",\"Survived\"]).size().unstack(\"Survived\").plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interactives Dashboard mit Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = train\n",
    "def plot_categorial(column):\n",
    "    %matplotlib agg\n",
    "    ab = df.groupby([column,\"Survived\"]).size().unstack(\"Survived\").plot(kind=\"bar\").get_figure()\n",
    "    return ab\n",
    "\n",
    "def plot_numerical(column):\n",
    "    %matplotlib agg\n",
    "    # peaks for survived/not survived passengers by their age\n",
    "    facet = sns.FacetGrid(df, hue=\"Survived\",aspect=4)\n",
    "    facet.map(sns.kdeplot,column,shade= True)\n",
    "    facet.set(xlim=(0, df[column].max()))\n",
    "    facet.add_legend()\n",
    "    return facet.fig\n",
    "    \n",
    "def plot_column(column):\n",
    "    if df[column].dtype == np.float:\n",
    "        fig = plot_numerical(column)\n",
    "    else:\n",
    "        fig = plot_categorial(column)\n",
    "    return fig\n",
    "    \n",
    "fig = plot_column(\"Age\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "pn.extension()\n",
    "cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "fig = pn.interact(plot_column, column=cols)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Aufgaben\n",
    "* Sammele für dich interessante Erkentnisse und Ideen, die später bei der Prognose von Überlebenden hilfreich sein könnten.\n",
    "* Analysiere die Spalte \"Embarked\" und versuche eine Erklärung zu finden, warum sich Hafen C von Q und S unterscheidet\n",
    "* Erweitere das Dashboard um einen interaktiven Titel, der das dargestellte beschreibt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erkentnisse der Datenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Warum sterben mehr Passagiere vom Abfahrtshafen C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Erweiterung Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Basic Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train_with_nas = train.copy()\n",
    "test_with_nas = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Missing Values\n",
    "\n",
    "Missing Values, also unbekannte Werte stellen für viele Machine Learning Algorithmen ein Problem dar (wenn auch nicht für alle), da sie im wesentlichen mit nummerischen Werten arbeiten. Grundsätzlich ist es daher eine gute Idee fehlende Werte zu ersetzen. Hierfür gibt es zahlreiche Möglichkeiten, wie etwa:\n",
    "\n",
    "* Das ersetzen mit einem fest definiertem Wert\n",
    "    * Für numerische Werte nutzt man den Durchschnittswert (average) oder den Mittelwert (median).\n",
    "    * Für kategorische Werte empfiehlt sich die häufigsten Klasse\n",
    "    \n",
    "* Das ersetzen mit einem repräsentativen Wert\n",
    "    * Equivalent zu oben, allerdings wird der Wert innerhalb einer repräsentativen Subgruppe gebildet\n",
    "    * Automatische Bildung mehrer Cluster (etwa via kNN)\n",
    "    \n",
    "* Das ersetzen mit einem algorithmisch bestimmten Werts\n",
    "    * Regressions- und Klassifikationsmodelle\n",
    "    * Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = train.append(test)\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "default_age = train.Age.median()\n",
    "\n",
    "for df in [train, test]:\n",
    "    df.Age.fillna(default_age, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "default_price = train.Fare.mean()\n",
    "\n",
    "for df in [train, test]:\n",
    "    df.Fare.fillna(default_price, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "default_harbor = train.Embarked.mode()[0]\n",
    "\n",
    "for df in [train, test]:\n",
    "    df.Embarked.fillna(default_harbor, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = train.append(test)\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Alternative** Scikit-Learn Missing Value Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train.Embarked.values.reshape(-1, 1)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "embarked_imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "embarked_imp.fit_transform(train.Embarked.values.reshape(-1, 1))\n",
    "without_nas = embarked_imp.transform(test.Embarked.values.reshape(-1, 1))\n",
    "\n",
    "# Check if there are still NAs?\n",
    "pd.Series(np.ravel(without_nas)).isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nicht nur Missing Values sind problematisch für Algorithmen, sondern auch andere nicht nummerische Werte. Zwar wandeln zahlreiche Verfahren etwa Boolean-Werte automatisch in eine 1/0 Darstellung um, dennoch empfiehlt es sich auch hier Zeichenketten (strings) und kategoriale Werte entsprechend umzuwandeln. Gängige Verfahren sind:\n",
    "\n",
    "* Binarize: Darstellung in Binärzahlen (1 und 0 für True und False)\n",
    "* [One Hot Encoding](http://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example)\n",
    "* Dummy Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "for df in [train, test]:\n",
    "    df['Sex'] = label_binarize(df.Sex, ['male', 'female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "harbour_encocer = LabelEncoder()\n",
    "harbour_encocer.fit(train.Embarked)\n",
    "for df in [train, test]:\n",
    "    df[\"Embarked\"] = harbour_encocer.transform(df.Embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(exclude=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df.drop([\"Name\",\"Ticket\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## einfaches Feature Engineering\n",
    "\n",
    "Nicht alle Informationen lasssen sich so standardisiert in maschinell verarbeitbare Daten überführen. Beim Feature Engineering geht es darum, neue spalten zu erstellen, die für die algorithmen zusätzliche, wertvolle Informationen berreitstellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Schiffskabine\n",
    "\n",
    "Einige Passagiere haben eine Kabinennummer, anhand derer sich eventuell auf die Position im Boot (Deck, Innen- oder Außenkabine, Rumpf- oder Heckbereich) schließen lassen könnte, jedoch ist dies nicht offensichtlich. Dennoch bietet aufgrund der vielen fehlenden Werte allein die Information, dass ein Passagier eine Kabine hatte (das war nicht selbstverständlich) eine wertvolle Information die wir nutzen wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "len(train.loc[train.Cabin.isna()]) / len(train.Cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df[\"has_cabin\"] = ~df.Cabin.isna()\n",
    "    \n",
    "for df in [train, test]:\n",
    "    df.drop(\"Cabin\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Familiengröße\n",
    "\n",
    "Im Datensatz finden sich die zwei Spalten SibSp (=Siblings/Spouses, also Ehegatten oder Geschwister) und Parch (Eltern / Kinder). Diese etwas verwirrende Aufteilung lässt sich deutlich einfacher darstellen, in dem wir beide Werte einfach als Familiengröße zusammenfassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.SibSp + df.Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df[\"family_size\"] = df.SibSp + df.Parch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Aufgaben\n",
    "\n",
    "* Überprüfe, wie das Feature Familiengröße im Verhältnis zur Überlebenswahrscheinlichkeit steht\n",
    "* Erstelle ein Feature, dass aussagt, ob eine Person alleine reist\n",
    "* Entferne alle Spalten, welche für das Modelltraining nicht benötigt werden\n",
    "* Erstelle eine Funktion, welche alle fehlenden Werte in einem DataFrame bereinigt und mache konfigurierbar, ob das DataFrame selbst oder eine Kopie bereinigt werden soll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Familiengröße"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Alleinreisenden-Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entfernen unnötiger Spalten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Missing Value Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Machine Learning (Modeling 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Überprüfe erneut, ob nur nummerische und boolean Werte vorkommen und fehlenden Werte mehr existieren (mit ausnahme von Survived im testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Check the again the data\n",
    "# There should be only bool and numeric columns and no NAs beside from Survived (which of course is unkown in the testset)\n",
    "df = train.append(test)\n",
    "pd.DataFrame(zip(df.columns, df.dtypes, df.isna().sum()), columns=[\"column\", \"type\", \"NAs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = train.drop(columns=\"Survived\")\n",
    "y = np.ravel(train[['Survived']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree._export import plot_tree\n",
    "figsize(20, 8)\n",
    "fig = plot_tree(classifier, label='root', feature_names = X.columns, impurity=True, filled=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(max_depth=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "figsize(20, 8)\n",
    "fig = plot_tree(classifier, label='root', feature_names = X.columns, impurity=True, filled=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "## Modell-Bewertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(predictions, y_test), columns=[\"predicted\", \"actual\"]).sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap((pd.DataFrame(cm)/len(predictions)).round(decimals=2), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Binäre Klassifikationsmetriken](static/metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### False Positive Rate / Fehler 1. Art \n",
    "\n",
    "Wie viele der positiven Ereignisse (Passagier überlebt) wurden falsch vorhergesagt?\n",
    "\n",
    "=> Bei wie vielen dachten wir, sie werden ertrinken, obwohl sie überlebt haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "false_positive_rate = fp / (fp + tn)\n",
    "false_positive_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### False Negative Rate / Fehler 2. Art \n",
    "\n",
    "Wie viele der negativen Ereignisse (verstorben) wurden falsch vorhergesagt?\n",
    "\n",
    "=> Bei wie vielen dachten wir, sie werden ertrinken, obwohl sie überlebt haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "false_negative_rate = fn / (tp + fn)\n",
    "false_negative_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### True Negative Rate / Specificity / Spezifität \n",
    "\n",
    "Wie viele der negativen Ereignisse (verstorben) haben wir korrekt vorhergesagt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "specificity = tn / (tn + fp)\n",
    "specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### True Positive Rate / Recall / Sensitivität\n",
    "\n",
    "Wie viele der positiven Ereignisse (überlebt) haben wir korrekt vorhergesagt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "recall = tp / (tp + fn)\n",
    "recall\n",
    "\n",
    "# oder auch\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Positive Predictive Value / Precision / Genauigkeit\n",
    "Wie viele der positiv vorhergesagten Ereignisse waren auch positiv (haben auch überlebt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "precision = tp/ (tp + fp)\n",
    "\n",
    "# oder auch\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Accuracy\n",
    "\n",
    "Wie viele der vorhersagen stimmen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "\n",
    "# oder auch\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Das harmonische Mittel zwischen Precision und Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "# oder auch\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modell-Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(X.columns, classifier.feature_importances_), columns=[\"feature\", \"importance\"])\\\n",
    ".set_index(\"feature\").sort_values(\"importance\")\\\n",
    ".plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(classifier, X, y, scoring = \"accuracy\", cv=10)\n",
    "print(cv_scores)\n",
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(classifier, X, y, scoring = \"accuracy\", cv=2)\n",
    "print(cv_scores)\n",
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From the [Scikit-Learn Documentation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes, return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "plot_learning_curve(classifier, \"Decision Tree max_depth=3\", X, y, axes=axes[:], cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "## Aufgaben\n",
    "* Erstelle eine Funktion, welche die wichtigsten Metriken berechnet und darstellt\n",
    "* Probiere verschiedene Parameter für den Entscheidungsbaum aus und analysiere die Auswirkungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verprobe unterschiedliche Modellparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "# Modeling 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "dt_hpt_params = dict()\n",
    "dt_hpt_params[\"max_depth\"] = [2,3,5,10,None]\n",
    "dt_hpt_params[\"min_samples_leaf\"] = [1,2,3,5,10]\n",
    "dt_hpt_params[\"min_samples_split\"] = [1, 2, 3,4,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt_random = RandomizedSearchCV(estimator = dt, param_distributions = dt_hpt_params,\\\n",
    "                               n_iter = 50, scoring=\"f1\", cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "dt_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "classifier = DecisionTreeClassifier(**dt_random.best_params_)\n",
    "classifier.fit(X_train, y_train)\n",
    "plot_learning_curve(classifier, \"Decision Tree\", X, y, axes=axes[:], cv=cv, n_jobs=4)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "diff = pd.Series(get_scores(y_test, predictions))-baseline\n",
    "print(diff)\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=[\"Survived\", \"Drown\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "plot_learning_curve(classifier, \"Decision Tree\", X, y, axes=axes[:], cv=cv, n_jobs=4)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "diff = pd.Series(get_scores(y_test, predictions))-baseline\n",
    "print(diff)\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=[\"Survived\", \"Drown\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich verschiedener Algorithmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "X_train = train.drop(columns=\"Survived\")\n",
    "y_train = train[['Survived']]\n",
    "\n",
    "classifiers = [DecisionTreeClassifier(), LogisticRegression(), KNeighborsClassifier(), GradientBoostingClassifier()]\n",
    "\n",
    "algorithm_names = []\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for classifier in classifiers:\n",
    "    classifier.random_state=42\n",
    "    algorithm_names.append(type(classifier).__name__)\n",
    "    cv_result = cross_val_score(classifier, X_train, y = y_train, scoring = \"f1\", cv = cv, n_jobs=-1)\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "    \n",
    "#algorithm_names = [\"SVC\",\"DecisionTree\",\"AdaBoost\",\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]\n",
    "cv_res = pd.DataFrame({\"mean\":cv_means,\"std\": cv_std,\"Algorithm\":algorithm_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(15,5)\n",
    "g = sns.barplot(\"mean\",\"Algorithm\",data = cv_res, xerr=cv_std)\n",
    "g.set_xlabel(\"Mean Accuracy\")\n",
    "g = g.set_title(\"Cross validation scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, len(classifiers), figsize=(20, 20))\n",
    "\n",
    "for i, estimator in enumerate(classifiers):\n",
    "    title = f\"{estimator.__class__.__name__}\"\n",
    "    plot_learning_curve(estimator, title, X, y, axes=axes[:, i],\n",
    "                        cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben\n",
    "\n",
    "* Erstelle ein möglichst gutes Klassifikations-Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Evaluation & Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile model_preperation.py\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "class ModelPreperation(TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self ):\n",
    "        self.title_encoder = LabelEncoder()\n",
    "        self.harbor_encoder = LabelEncoder()\n",
    "        pass\n",
    "     \n",
    "    def fit( self, X, y=None ):\n",
    "        self.default_age = X.Age.median()\n",
    "        self.default_price = X.Fare.mean()\n",
    "        self.default_harbor = X.Embarked.mode()[0]\n",
    "        self.harbor_encoder.fit(X.Embarked.astype(\"str\"))\n",
    "        return self\n",
    "        \n",
    "    def transform( self, df):\n",
    "        print(df)\n",
    "        df.Age.fillna(self.default_age, inplace=True)\n",
    "        df.Fare.fillna(self.default_price, inplace=True)\n",
    "        df.Embarked.fillna(self.default_harbor, inplace=True)\n",
    "        df[\"has_cabin\"] = ~df.Cabin.isna()\n",
    "        df['Sex'] = label_binarize(df.Sex, ['male', 'female'])\n",
    "        df[\"Embarked\"] = self.harbor_encoder.transform(df.Embarked)\n",
    "        df.drop([\"Cabin\",\"Name\",\"Ticket\",\"PassengerId\"], axis=1, inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipe():\n",
    "    train = pd.read_csv(\"./data/titanic/train.csv\")\n",
    "    X = train.drop(columns=\"Survived\")\n",
    "    y = np.ravel(train[['Survived']])\n",
    "\n",
    "    gb_params = {'n_estimators': 200,'min_samples_split': 16,'min_samples_leaf': 16,'max_features': 5,'max_depth': 3,'learning_rate': 0.25}\n",
    "    pipe = Pipeline(steps=[(\"prepare\",ModelPreperation()), (\"clr\",GradientBoostingClassifier(**gb_params))])\n",
    "    return pipe.fit(X, y)\n",
    "pipe = train_pipe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Build API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile api.py\n",
    "\n",
    "import pickle\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from model_preperation import ModelPreperation\n",
    "import model_preperation\n",
    "import joblib\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline \n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "class Passenger(BaseModel):\n",
    "    PassengerId: float = 1\n",
    "    Pclass: str = 3\n",
    "    Name: str = 'Nico, Rare. Kreiling'\n",
    "    Sex: str = 'F'\n",
    "    Age: int = 30\n",
    "    SibSp: float = 0\n",
    "    Parch: float = 3\n",
    "    Ticket: str = ''\n",
    "    Fare: float = 100\n",
    "    Cabin: str = ''\n",
    "    Embarked: str = 'C'\n",
    "        \n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Hello World\"}\n",
    "\n",
    "@app.get(\"/survived/passanger_id/{user_id}\")\n",
    "async def read_item(user_id):\n",
    "    return {\"item_id\": user_id}\n",
    "\n",
    "@app.post(\"/survived/custom\")\n",
    "async def root(passenger: Passenger):\n",
    "    prediction = pipe.predict(pd.Series(dict(passenger)).to_frame().transpose())\n",
    "    if prediction[0] == 0:\n",
    "        return {\"message\": \"Sorry, you die!\"}\n",
    "    else:\n",
    "        return {\"message\": \"Yeaaah, you will survive :)\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "form_data = {\n",
    "    \"Pclass\": 3, \n",
    "    \"Name\": 'Nico, Mr. Kreiling',\n",
    "    \"Sex\": 'M',\n",
    "    \"Age\": 30,\n",
    "    \"SibSp\": 4,\n",
    "    \"Parch\": 0,\n",
    "    \"Fare\": 100,\n",
    "    \"Embarked\": 'C'\n",
    "}\n",
    "r = requests.post('http://127.0.0.1:8000/survived/custom', json=form_data)\n",
    "r.status_code\n",
    "r.json()[\"message\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw.Name.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train_raw.Name.str.extract(' ([A-Za-z]+)\\.', expand=False).value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_title(df):\n",
    "    titles = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    titles = titles.replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'],'Rare')\n",
    "    titles = titles.replace('Mlle','Miss')\n",
    "    titles = titles.replace('Ms','Miss')\n",
    "    titles = titles.replace('Mme','Mrs')\n",
    "    return titles\n",
    "\n",
    "get_title(train_raw).value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train[\"title\"] = get_title(train_raw)\n",
    "test[\"title\"] = get_title(test_raw)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "title_encoder = LabelEncoder()\n",
    "title_encoder.fit(train.title)\n",
    "for df in [train, test]:\n",
    "    df[\"title\"] = title_encoder.transform(df.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Auto-Features (PClass * Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df[\"comb\"] = df.Pclass * df.Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe \n",
    "Analysiere den Einfluss der neuen Features auf dein Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bucket Numerical Features and 1-hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#float_cols = list(train.dtypes[train.dtypes == float].index)\n",
    "float_cols = ['Age', 'Fare', 'comb', 'family_size']\n",
    "scaler.fit(train[float_cols])\n",
    "\n",
    "for df in [train, test]:\n",
    "    df[float_cols] = scaler.transform(df[float_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(list(train.dtypes[train.dtypes == int].index))\n",
    "dummie_cols = ['Pclass', 'Embarked', 'title']    \n",
    "for c in dummie_cols:  \n",
    "    print(c)\n",
    "    for df in [train, test]:\n",
    "        if len(df[c].unique()) > 2:\n",
    "            dummies = pd.get_dummies(df[c], prefix=c, drop_first=False)\n",
    "            for d in dummies:\n",
    "                df[d] = dummies[d]\n",
    "            df.drop(columns=c, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds]",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
